{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Module 11: Packaging, Reuse & ML Deployment Lite\n",
                "\n",
                "**Learning Objectives:**\n",
                "- Scaffold and structure an analytics/ML Python package\n",
                "- Write reusable utility modules for wrangling and validation\n",
                "- Save and load ML models using `joblib`/`pickle`\n",
                "- Write documentation and reusable templates\n",
                "- Build simple CLI interfaces for automated pipeline runs\n",
                "\n",
                "> **Why does this matter?** Notebooks are great for exploration, but production data systems are built from reusable modules, deployed as scripts, and served via APIs or CLIs. This module bridges the gap between a notebook prototype and a working system."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import sys\n",
                "import json\n",
                "import time\n",
                "import pickle\n",
                "import joblib\n",
                "import argparse\n",
                "import textwrap\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "from pathlib import Path\n",
                "from datetime import datetime\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "from sklearn.pipeline import Pipeline\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import r2_score, accuracy_score\n",
                "\n",
                "os.makedirs('models', exist_ok=True)\n",
                "os.makedirs('src', exist_ok=True)\n",
                "print(\"Environment ready!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 1. Project Scaffolding for Analytics + ML\n",
                "\n",
                "A well-structured Python package makes your code importable, testable, and shareable."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Write a clean src package structure\n",
                "src = Path('src')\n",
                "\n",
                "# __init__.py\n",
                "(src / '__init__.py').write_text(textwrap.dedent(\"\"\"\n",
                "# src/__init__.py\n",
                "# Entry point for the analytics package.\n",
                "from .clean import clean_dataframe\n",
                "from .validate import DataValidator\n",
                "from .model import train_model, predict\n",
                "\"\"\").strip())\n",
                "\n",
                "print(\"src/__init__.py written.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 2. Utility Module: Wrangling (`src/clean.py`)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "clean_module = textwrap.dedent(\"\"\"\n",
                "# src/clean.py\n",
                "\"\"\"Reusable data cleaning utilities.\"\"\"\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "from typing import Optional, List, Dict\n",
                "\n",
                "\n",
                "def strip_whitespace(df: pd.DataFrame, columns: Optional[List[str]] = None) -> pd.DataFrame:\n",
                "    \"\"\"Strip leading/trailing whitespace from string columns.\"\"\"\n",
                "    cols = columns or df.select_dtypes(include='object').columns.tolist()\n",
                "    for col in cols:\n",
                "        df[col] = df[col].str.strip()\n",
                "    return df\n",
                "\n",
                "\n",
                "def drop_duplicates_logged(df: pd.DataFrame, subset=None, logger=None) -> pd.DataFrame:\n",
                "    \"\"\"Drop duplicates and log the count removed.\"\"\"\n",
                "    before = len(df)\n",
                "    df = df.drop_duplicates(subset=subset)\n",
                "    removed = before - len(df)\n",
                "    msg = f\"Removed {removed} duplicate rows.\"\n",
                "    if logger:\n",
                "        logger.info(msg)\n",
                "    else:\n",
                "        print(msg)\n",
                "    return df\n",
                "\n",
                "\n",
                "def impute_columns(df: pd.DataFrame, strategy: Dict[str, str]) -> pd.DataFrame:\n",
                "    \"\"\"\n",
                "    Impute missing values per column.\n",
                "    strategy: dict of {column: 'mean' | 'median' | 'mode' | <literal>}\n",
                "    \"\"\"\n",
                "    for col, method in strategy.items():\n",
                "        if col not in df.columns:\n",
                "            continue\n",
                "        if method == 'mean':\n",
                "            df[col] = df[col].fillna(df[col].mean())\n",
                "        elif method == 'median':\n",
                "            df[col] = df[col].fillna(df[col].median())\n",
                "        elif method == 'mode':\n",
                "            df[col] = df[col].fillna(df[col].mode()[0])\n",
                "        else:\n",
                "            df[col] = df[col].fillna(method)\n",
                "    return df\n",
                "\n",
                "\n",
                "def encode_categoricals(df: pd.DataFrame, columns: List[str], drop_first=True) -> pd.DataFrame:\n",
                "    \"\"\"One-hot encode a list of categorical columns.\"\"\"\n",
                "    return pd.get_dummies(df, columns=columns, drop_first=drop_first)\n",
                "\n",
                "\n",
                "def clean_dataframe(df: pd.DataFrame, config: dict) -> pd.DataFrame:\n",
                "    \"\"\"\n",
                "    Master cleaning function driven by a config dict.\n",
                "    config keys: strip_cols, dedup_cols, impute, encode_cols\n",
                "    \"\"\"\n",
                "    df = df.copy()\n",
                "    if config.get('strip_cols'):\n",
                "        df = strip_whitespace(df, config['strip_cols'])\n",
                "    if config.get('dedup_cols') is not None:\n",
                "        df = drop_duplicates_logged(df, subset=config['dedup_cols'] or None)\n",
                "    if config.get('impute'):\n",
                "        df = impute_columns(df, config['impute'])\n",
                "    if config.get('encode_cols'):\n",
                "        df = encode_categoricals(df, config['encode_cols'])\n",
                "    return df\n",
                "\"\"\")\n",
                "\n",
                "(src / 'clean.py').write_text(clean_module)\n",
                "print(\"src/clean.py written.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 3. Utility Module: Validation (`src/validate.py`)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "validate_module = textwrap.dedent(\"\"\"\n",
                "# src/validate.py\n",
                "\"\"\"Reusable data validation utilities.\"\"\"\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "from typing import List, Optional\n",
                "\n",
                "\n",
                "class DataValidator:\n",
                "    \"\"\"Chainable data validation class.\"\"\"\n",
                "\n",
                "    def __init__(self, df: pd.DataFrame):\n",
                "        self.df = df\n",
                "        self.errors: dict = {}\n",
                "        self.warnings: dict = {}\n",
                "\n",
                "    def required_columns(self, columns: List[str]) -> 'DataValidator':\n",
                "        \"\"\"Check that required columns exist.\"\"\"\n",
                "        missing = [c for c in columns if c not in self.df.columns]\n",
                "        if missing:\n",
                "            self.errors['missing_columns'] = f\"Columns not found: {missing}\"\n",
                "        return self\n",
                "\n",
                "    def no_nulls(self, columns: List[str]) -> 'DataValidator':\n",
                "        \"\"\"Check that columns have no null values.\"\"\"\n",
                "        for col in columns:\n",
                "            count = self.df[col].isnull().sum()\n",
                "            if count > 0:\n",
                "                self.errors[f'{col}_nulls'] = f\"{count} null values found.\"\n",
                "        return self\n",
                "\n",
                "    def value_range(self, col: str, min_val=None, max_val=None) -> 'DataValidator':\n",
                "        \"\"\"Check numeric values fall within [min_val, max_val].\"\"\"\n",
                "        if min_val is not None and (self.df[col] < min_val).any():\n",
                "            self.errors[f'{col}_below_min'] = f\"Values below {min_val} found.\"\n",
                "        if max_val is not None and (self.df[col] > max_val).any():\n",
                "            self.warnings[f'{col}_above_max'] = f\"Values above {max_val} found.\"\n",
                "        return self\n",
                "\n",
                "    def allowed_values(self, col: str, allowed: list) -> 'DataValidator':\n",
                "        \"\"\"Check all values are in the allowed set.\"\"\"\n",
                "        invalid = self.df[~self.df[col].isin(allowed)][col].unique()\n",
                "        if len(invalid):\n",
                "            self.errors[f'{col}_invalid_values'] = f\"Unexpected values: {invalid.tolist()}\"\n",
                "        return self\n",
                "\n",
                "    def row_count(self, min_rows: int) -> 'DataValidator':\n",
                "        \"\"\"Check that DataFrame has at least min_rows rows.\"\"\"\n",
                "        if len(self.df) < min_rows:\n",
                "            self.errors['row_count'] = f\"Expected >= {min_rows} rows, got {len(self.df)}.\"\n",
                "        return self\n",
                "\n",
                "    def generate_report(self) -> str:\n",
                "        \"\"\"Return a formatted validation summary.\"\"\"\n",
                "        lines = ['=== Data Validation Report ===']\n",
                "        if not self.errors and not self.warnings:\n",
                "            lines.append('âœ… All checks passed!')\n",
                "        for k, v in self.errors.items():\n",
                "            lines.append(f'âŒ ERROR   [{k}]: {v}')\n",
                "        for k, v in self.warnings.items():\n",
                "            lines.append(f'âš ï¸  WARNING [{k}]: {v}')\n",
                "        return '\\n'.join(lines)\n",
                "\n",
                "    def is_valid(self) -> bool:\n",
                "        return len(self.errors) == 0\n",
                "\"\"\")\n",
                "\n",
                "(src / 'validate.py').write_text(validate_module)\n",
                "print(\"src/validate.py written.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 4. Utility Module: Model (`src/model.py`)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_module = textwrap.dedent(\"\"\"\n",
                "# src/model.py\n",
                "\"\"\"ML training, saving, and prediction utilities.\"\"\"\n",
                "\n",
                "import joblib\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "from typing import List\n",
                "from pathlib import Path\n",
                "from sklearn.pipeline import Pipeline\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.linear_model import LinearRegression\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import r2_score, mean_squared_error\n",
                "\n",
                "\n",
                "def build_regression_pipeline(estimator=None):\n",
                "    \"\"\"Build a sklearn Pipeline: scaler + estimator.\"\"\"\n",
                "    estimator = estimator or LinearRegression()\n",
                "    return Pipeline([\n",
                "        ('scaler', StandardScaler()),\n",
                "        ('model', estimator)\n",
                "    ])\n",
                "\n",
                "\n",
                "def train_model(df: pd.DataFrame, feature_cols: List[str], target_col: str,\n",
                "                model_path: str = 'models/model.pkl', test_size=0.2, random_state=42):\n",
                "    \"\"\"Train, evaluate, and save a regression model.\"\"\"\n",
                "    X = df[feature_cols]\n",
                "    y = df[target_col]\n",
                "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
                "\n",
                "    pipeline = build_regression_pipeline()\n",
                "    pipeline.fit(X_train, y_train)\n",
                "\n",
                "    y_pred = pipeline.predict(X_test)\n",
                "    metrics = {\n",
                "        'r2': r2_score(y_test, y_pred),\n",
                "        'rmse': np.sqrt(mean_squared_error(y_test, y_pred)),\n",
                "        'n_train': len(X_train),\n",
                "        'n_test': len(X_test)\n",
                "    }\n",
                "\n",
                "    Path(model_path).parent.mkdir(parents=True, exist_ok=True)\n",
                "    joblib.dump(pipeline, model_path)\n",
                "\n",
                "    return pipeline, metrics\n",
                "\n",
                "\n",
                "def predict(input_df: pd.DataFrame, model_path: str) -> np.ndarray:\n",
                "    \"\"\"Load a saved model and make predictions.\"\"\"\n",
                "    pipeline = joblib.load(model_path)\n",
                "    return pipeline.predict(input_df)\n",
                "\"\"\")\n",
                "\n",
                "(src / 'model.py').write_text(model_module)\n",
                "print(\"src/model.py written.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 5. Exporting ML Models: joblib vs pickle\n",
                "\n",
                "| Method | Best For | Pros | Cons |\n",
                "|---|---|---|---|\n",
                "| `joblib.dump` | sklearn models (especially with numpy arrays) | Faster for large arrays, compression support | joblib-only |\n",
                "| `pickle` | Any Python object | Universal | Slower for large arrays |\n",
                "| `model.save()` | TensorFlow/Keras | Native format | Framework-specific |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train a model to demonstrate saving/loading\n",
                "np.random.seed(42)\n",
                "n = 1000\n",
                "demo_df = pd.DataFrame({\n",
                "    'years_exp': np.random.randint(0, 30, n),\n",
                "    'performance': np.random.randint(50, 100, n),\n",
                "    'education': np.random.choice([0, 1, 2], n),\n",
                "    'salary': 30000 + np.random.randint(0, 30, n) * 2500 + np.random.normal(0, 4000, n)\n",
                "})\n",
                "\n",
                "feature_cols = ['years_exp', 'performance', 'education']\n",
                "X = demo_df[feature_cols]\n",
                "y = demo_df['salary']\n",
                "\n",
                "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "\n",
                "# Build and train a sklearn Pipeline (scaler + model combined)\n",
                "pipe = Pipeline([('scaler', StandardScaler()), ('model', LinearRegression())])\n",
                "pipe.fit(X_tr, y_tr)\n",
                "\n",
                "r2 = r2_score(y_te, pipe.predict(X_te))\n",
                "print(f\"Pipeline trained. RÂ² on test: {r2:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save with joblib (recommended for sklearn)\n",
                "joblib_path = 'models/salary_pipeline.pkl'\n",
                "joblib.dump(pipe, joblib_path, compress=3)\n",
                "print(f\"Saved with joblib: {joblib_path} ({os.path.getsize(joblib_path)} bytes)\")\n",
                "\n",
                "# Save with pickle\n",
                "pickle_path = 'models/salary_pipeline_pickle.pkl'\n",
                "with open(pickle_path, 'wb') as f:\n",
                "    pickle.dump(pipe, f)\n",
                "print(f\"Saved with pickle: {pickle_path} ({os.path.getsize(pickle_path)} bytes)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load and use the saved pipeline\n",
                "loaded_pipe = joblib.load(joblib_path)\n",
                "\n",
                "# Predict on new data\n",
                "new_candidate = pd.DataFrame({'years_exp': [10], 'performance': [88], 'education': [2]})\n",
                "predicted_salary = loaded_pipe.predict(new_candidate)[0]\n",
                "print(f\"Predicted salary for new candidate: ${predicted_salary:,.2f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 6. Model Versioning & Metadata\n",
                "\n",
                "Always save metadata alongside your model so you know exactly what was used."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def save_model_with_metadata(pipeline, metrics, feature_cols, model_dir='models', name='salary_model'):\n",
                "    \"\"\"Save a model pipeline alongside a JSON metadata file.\"\"\"\n",
                "    os.makedirs(model_dir, exist_ok=True)\n",
                "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
                "    model_path = os.path.join(model_dir, f\"{name}_{timestamp}.pkl\")\n",
                "    meta_path  = os.path.join(model_dir, f\"{name}_{timestamp}_meta.json\")\n",
                "    latest_path = os.path.join(model_dir, f\"{name}_latest.pkl\")\n",
                "\n",
                "    joblib.dump(pipeline, model_path, compress=3)\n",
                "    joblib.dump(pipeline, latest_path, compress=3)  # Always overwrite 'latest'\n",
                "\n",
                "    metadata = {\n",
                "        'model_path': model_path,\n",
                "        'trained_at': timestamp,\n",
                "        'features': feature_cols,\n",
                "        'metrics': metrics,\n",
                "        'pipeline_steps': [s[0] for s in pipeline.steps]\n",
                "    }\n",
                "    with open(meta_path, 'w') as f:\n",
                "        json.dump(metadata, f, indent=2)\n",
                "\n",
                "    print(f\"âœ… Model saved: {model_path}\")\n",
                "    print(f\"ðŸ“‹ Metadata:   {meta_path}\")\n",
                "    return metadata\n",
                "\n",
                "metrics = {'r2': r2, 'rmse': 5000.0, 'n_train': 800, 'n_test': 200}\n",
                "meta = save_model_with_metadata(pipe, metrics, feature_cols)\n",
                "print(json.dumps(meta, indent=2))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 7. Building a Command-Line Interface (CLI)\n",
                "\n",
                "A CLI lets your pipeline be triggered from a terminal, cron job, or n8n."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Write a complete CLI pipeline script\n",
                "cli_script = textwrap.dedent(\"\"\"\n",
                "#!/usr/bin/env python\n",
                "# scripts/run_pipeline.py\n",
                "\"\"\"\n",
                "Full ML pipeline CLI.\n",
                "Usage:\n",
                "  python run_pipeline.py --input data/raw/employees.csv --output models/ --target salary\n",
                "  python run_pipeline.py --input data/raw/employees.csv --target salary --mode predict --model models/salary_model_latest.pkl\n",
                "\"\"\"\n",
                "\n",
                "import argparse\n",
                "import json\n",
                "import sys\n",
                "import logging\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import joblib\n",
                "from pathlib import Path\n",
                "from datetime import datetime\n",
                "from sklearn.pipeline import Pipeline\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.linear_model import LinearRegression\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import r2_score\n",
                "\n",
                "\n",
                "logging.basicConfig(\n",
                "    level=logging.INFO,\n",
                "    format='%(asctime)s | %(levelname)-8s | %(message)s',\n",
                "    handlers=[logging.StreamHandler(), logging.FileHandler('logs/pipeline.log')]\n",
                ")\n",
                "log = logging.getLogger('pipeline')\n",
                "\n",
                "\n",
                "def parse_args():\n",
                "    parser = argparse.ArgumentParser(description='ML Pipeline Runner')\n",
                "    parser.add_argument('--input',   required=True,  help='Path to input CSV file')\n",
                "    parser.add_argument('--target',  required=True,  help='Target column name')\n",
                "    parser.add_argument('--output',  default='models', help='Output directory for models')\n",
                "    parser.add_argument('--mode',    choices=['train', 'predict'], default='train')\n",
                "    parser.add_argument('--model',   default=None,   help='Path to saved model (for predict mode)')\n",
                "    parser.add_argument('--test-size', type=float,   default=0.2)\n",
                "    return parser.parse_args()\n",
                "\n",
                "\n",
                "def train_pipeline(df, target_col, test_size, output_dir):\n",
                "    feature_cols = [c for c in df.select_dtypes(include=[np.number]).columns if c != target_col]\n",
                "    X, y = df[feature_cols], df[target_col]\n",
                "    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=test_size, random_state=42)\n",
                "\n",
                "    log.info(f\"Training on {len(X_tr)} samples, testing on {len(X_te)} samples.\")\n",
                "    pipe = Pipeline([('scaler', StandardScaler()), ('model', LinearRegression())])\n",
                "    pipe.fit(X_tr, y_tr)\n",
                "\n",
                "    r2 = r2_score(y_te, pipe.predict(X_te))\n",
                "    log.info(f\"RÂ² score: {r2:.4f}\")\n",
                "\n",
                "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
                "    ts = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
                "    model_path = f\"{output_dir}/model_{ts}.pkl\"\n",
                "    joblib.dump(pipe, model_path)\n",
                "    joblib.dump(pipe, f\"{output_dir}/model_latest.pkl\")\n",
                "    log.info(f\"Model saved to {model_path}\")\n",
                "\n",
                "    print(json.dumps({'status': 'success', 'r2': r2, 'model_path': model_path}))\n",
                "\n",
                "\n",
                "def predict_pipeline(df, target_col, model_path):\n",
                "    feature_cols = [c for c in df.select_dtypes(include=[np.number]).columns if c != target_col]\n",
                "    pipe = joblib.load(model_path)\n",
                "    predictions = pipe.predict(df[feature_cols])\n",
                "    df['prediction'] = predictions\n",
                "    output = df[['prediction']].to_dict(orient='records')\n",
                "    print(json.dumps({'status': 'success', 'predictions': output[:5], 'total': len(output)}))\n",
                "\n",
                "\n",
                "def main():\n",
                "    args = parse_args()\n",
                "    log.info(f\"Loading data from {args.input}\")\n",
                "    df = pd.read_csv(args.input)\n",
                "    log.info(f\"Loaded {len(df)} rows, {len(df.columns)} columns.\")\n",
                "\n",
                "    if args.mode == 'train':\n",
                "        train_pipeline(df, args.target, args.test_size, args.output)\n",
                "    elif args.mode == 'predict':\n",
                "        if not args.model:\n",
                "            log.error(\"--model is required for predict mode.\")\n",
                "            sys.exit(1)\n",
                "        predict_pipeline(df, args.target, args.model)\n",
                "\n",
                "\n",
                "if __name__ == '__main__':\n",
                "    main()\n",
                "\"\"\")\n",
                "\n",
                "os.makedirs('scripts', exist_ok=True)\n",
                "with open('scripts/run_pipeline.py', 'w') as f:\n",
                "    f.write(cli_script)\n",
                "\n",
                "print(\"âœ… scripts/run_pipeline.py written!\")\n",
                "print(\"\\nUsage examples:\")\n",
                "print(\"  python scripts/run_pipeline.py --input data/raw/employees.csv --target salary\")\n",
                "print(\"  python scripts/run_pipeline.py --input data/raw/employees.csv --target salary --mode predict --model models/model_latest.pkl\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 8. Documentation: Auto-generating Docstrings & READMEs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# README template generator\n",
                "def generate_readme(project_name, description, features, usage_example, output_path='README.md'):\n",
                "    features_md = '\\n'.join(f'- {f}' for f in features)\n",
                "    readme = f\"\"\"# {project_name}\n",
                "\n",
                "{description}\n",
                "\n",
                "## Features\n",
                "\n",
                "{features_md}\n",
                "\n",
                "## Installation\n",
                "\n",
                "```bash\n",
                "python -m venv venv\n",
                "source venv/bin/activate  # Windows: venv\\\\Scripts\\\\activate\n",
                "pip install -r requirements.txt\n",
                "```\n",
                "\n",
                "## Usage\n",
                "\n",
                "```bash\n",
                "{usage_example}\n",
                "```\n",
                "\n",
                "## Project Structure\n",
                "\n",
                "```\n",
                "src/         Reusable modules\n",
                "scripts/     CLI pipeline runners\n",
                "data/        Raw and processed datasets\n",
                "models/      Saved ML model artifacts\n",
                "logs/        Pipeline execution logs\n",
                "```\n",
                "\n",
                "## License\n",
                "\n",
                "MIT\n",
                "\"\"\"\n",
                "    with open(output_path, 'w') as f:\n",
                "        f.write(readme)\n",
                "    print(f\"README written to {output_path}\")\n",
                "    return readme\n",
                "\n",
                "readme = generate_readme(\n",
                "    'Salary Prediction Pipeline',\n",
                "    'An end-to-end ML pipeline for predicting employee salaries from HR data.',\n",
                "    [\n",
                "        'Chunked CSV ingestion for large files',\n",
                "        'Configurable data cleaning and validation',\n",
                "        'Sklearn Pipeline with StandardScaler + LinearRegression',\n",
                "        'CLI interface for training and prediction',\n",
                "        'Model versioning with metadata JSON'\n",
                "    ],\n",
                "    'python scripts/run_pipeline.py --input data/raw/employees.csv --target salary'\n",
                ")\n",
                "print(readme[:800])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 9. Reusable Pipeline Template\n",
                "\n",
                "The master pattern for any production ML pipeline:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# REUSABLE ML PIPELINE TEMPLATE\n",
                "# ============================================================\n",
                "\n",
                "PIPELINE_CONFIG = {\n",
                "    'data_path': 'data/raw/employees.csv',\n",
                "    'target_col': 'salary',\n",
                "    'feature_cols': ['years_exp', 'performance', 'education'],\n",
                "    'clean': {\n",
                "        'impute': {'years_exp': 'median', 'performance': 'mean'},\n",
                "        'encode_cols': []  # categorical cols to one-hot encode\n",
                "    },\n",
                "    'model_dir': 'models',\n",
                "    'test_size': 0.2\n",
                "}\n",
                "\n",
                "def run_ml_pipeline(config: dict):\n",
                "    \"\"\"Execute the full ML pipeline from config.\"\"\"\n",
                "    print(\"\\n\" + \"=\"*50)\n",
                "    print(f\"Pipeline started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
                "    print(\"=\"*50)\n",
                "\n",
                "    # 1. Load data\n",
                "    print(\"[1/5] Loading data...\")\n",
                "    demo_df = pd.DataFrame({\n",
                "        'years_exp': np.random.randint(0, 30, 1000),\n",
                "        'performance': np.random.randint(50, 100, 1000),\n",
                "        'education': np.random.choice([0, 1, 2], 1000),\n",
                "        'salary': 30000 + np.random.randint(0, 30, 1000) * 2500\n",
                "    })\n",
                "\n",
                "    # 2. Validate\n",
                "    print(\"[2/5] Validating...\")\n",
                "    from src.validate import DataValidator\n",
                "    v = (DataValidator(demo_df)\n",
                "         .required_columns(config['feature_cols'] + [config['target_col']])\n",
                "         .no_nulls(config['feature_cols'])\n",
                "         .row_count(50))\n",
                "    print(v.generate_report())\n",
                "    if not v.is_valid():\n",
                "        raise ValueError(\"Validation failed. Aborting pipeline.\")\n",
                "\n",
                "    # 3. Feature engineering (basic)\n",
                "    print(\"[3/5] Feature engineering...\")\n",
                "    X = demo_df[config['feature_cols']]\n",
                "    y = demo_df[config['target_col']]\n",
                "\n",
                "    # 4. Train\n",
                "    print(\"[4/5] Training model...\")\n",
                "    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=config['test_size'], random_state=42)\n",
                "    pipe = Pipeline([('scaler', StandardScaler()), ('model', LinearRegression())])\n",
                "    pipe.fit(X_tr, y_tr)\n",
                "    r2 = r2_score(y_te, pipe.predict(X_te))\n",
                "    print(f\"   RÂ² = {r2:.4f}\")\n",
                "\n",
                "    # 5. Save\n",
                "    print(\"[5/5] Saving model...\")\n",
                "    os.makedirs(config['model_dir'], exist_ok=True)\n",
                "    model_path = os.path.join(config['model_dir'], 'model_latest.pkl')\n",
                "    joblib.dump(pipe, model_path)\n",
                "    print(f\"   Saved to: {model_path}\")\n",
                "\n",
                "    print(\"\\nâœ… Pipeline complete!\")\n",
                "    return {'r2': r2, 'model_path': model_path}\n",
                "\n",
                "run_ml_pipeline(PIPELINE_CONFIG)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 10. Exercises\n",
                "\n",
                "1. Add a `type_check` method to `DataValidator` that verifies column dtypes match expected types.\n",
                "2. Extend `save_model_with_metadata` to also log the Python version, sklearn version, and dataset row count.\n",
                "3. Modify `run_pipeline.py` to support `--config path/to/config.json` so all settings can be driven from a file.\n",
                "4. Write a `src/report.py` module with a `generate_model_card(metadata)` function that prints a formatted summary of the model.\n",
                "5. Package the `src/` module by writing a `setup.py` or `pyproject.toml`. Install it with `pip install -e .` and import it in a fresh Python session."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.9.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}