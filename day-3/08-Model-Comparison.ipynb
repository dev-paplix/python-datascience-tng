{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# The Battle of Algorithms: Model Comparison\n",
                "\n",
                "## Selecting the Best Model\n",
                "\n",
                "We have tried Linear Regression, Random Forests, and XGBoost individually.\n",
                "Now, we run a **systematic benchmark** to decide which algorithm is truly the best for predicting **customer total transaction amounts** in Malaysia.\n",
                "\n",
                "### The Contenders\n",
                "1. **Linear Regression**: The baseline.\n",
                "2. **Support Vector Regressor (SVR)**: Powerful for smaller datasets.\n",
                "3. **Random Forest**: Robust ensemble method.\n",
                "4. **XGBoost**: Gradient boosting machine."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "# Models\n",
                "from sklearn.linear_model import LinearRegression\n",
                "from sklearn.svm import SVR\n",
                "from sklearn.ensemble import RandomForestRegressor\n",
                "import xgboost as xgb\n",
                "\n",
                "# Evaluation\n",
                "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
                "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
                "from sklearn.metrics import mean_squared_error, r2_score\n",
                "import joblib  # For saving the model\n",
                "\n",
                "%matplotlib inline\n",
                "sns.set_theme(style=\"whitegrid\")\n",
                "plt.rcParams['figure.figsize'] = (10, 6)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Data Preparation Pipeline\n",
                "\n",
                "To ensure a fair comparison, all models use the same data.\n",
                "Since SVR and Linear Regression are scale-sensitive, we **scale** the features.\n",
                "Tree-based models (RF, XGB) don't need it, but it won't hurt them."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load data\n",
                "df = pd.read_csv(\"dummy_malaysia_customer_transactions_2025.csv\")\n",
                "\n",
                "# Encode categorical features\n",
                "le_region = LabelEncoder()\n",
                "le_quarter = LabelEncoder()\n",
                "df['region_encoded'] = le_region.fit_transform(df['region'].fillna('Unknown'))\n",
                "df['quarter_encoded'] = le_quarter.fit_transform(df['quarter'].fillna('Unknown'))\n",
                "\n",
                "features = ['region_encoded', 'quarter_encoded', 'number_of_purchases']\n",
                "target = 'total_transaction_amount'\n",
                "\n",
                "data = df[features + [target]].dropna()\n",
                "X = data[features]\n",
                "y = data[target]\n",
                "\n",
                "# Split\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "\n",
                "# Scale\n",
                "scaler = StandardScaler()\n",
                "X_train_scaled = scaler.fit_transform(X_train)\n",
                "X_test_scaled = scaler.transform(X_test)\n",
                "\n",
                "print(\"Data prepared and scaled.\")\n",
                "print(f\"Training samples: {len(X_train)}, Test samples: {len(X_test)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Setting up the Benchmark\n",
                "\n",
                "We define a list of models and evaluate each with **10-Fold Cross-Validation**.\n",
                "We collect `R2` scores for each fold to visualize stability."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define models\n",
                "models = []\n",
                "models.append(('Linear', LinearRegression()))\n",
                "models.append(('SVR', SVR()))\n",
                "models.append(('RandomForest', RandomForestRegressor(n_estimators=100, random_state=42)))\n",
                "models.append(('XGBoost', xgb.XGBRegressor(objective='reg:squarederror', seed=42)))\n",
                "\n",
                "# Iterate and evaluate\n",
                "results = []\n",
                "names = []\n",
                "\n",
                "print(\"--- Cross-Validation Results (R2 Score) ---\")\n",
                "\n",
                "for name, model in models:\n",
                "    kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
                "    cv_results = cross_val_score(model, X_train_scaled, y_train, cv=kfold, scoring='r2')\n",
                "    results.append(cv_results)\n",
                "    names.append(name)\n",
                "    print(f\"{name}: {cv_results.mean():.4f} (+/- {cv_results.std() * 2:.4f})\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Visualizing the Winner\n",
                "\n",
                "A boxplot compares algorithms by showing median accuracy and spread (stability)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(12, 6))\n",
                "plt.boxplot(results, labels=names, patch_artist=True,\n",
                "            boxprops=dict(facecolor=\"lightblue\", color=\"blue\"),\n",
                "            medianprops=dict(color=\"red\"))\n",
                "\n",
                "plt.title('Algorithm Comparison: R2 Score Distribution (Customer Transactions)', fontsize=14)\n",
                "plt.ylabel('R2 Score (Higher is Better)')\n",
                "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Final Training and Saving\n",
                "\n",
                "Based on the results above, we select the best model (usually XGBoost or Random Forest).\n",
                "We train it on the ENTIRE training set and save it for production use."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Let's assume XGBoost won (if not, change this line!)\n",
                "best_model_name = 'XGBoost'\n",
                "final_model = xgb.XGBRegressor(objective='reg:squarederror', seed=42)\n",
                "\n",
                "# Train on full training data\n",
                "final_model.fit(X_train_scaled, y_train)\n",
                "\n",
                "# Final Test Evaluation\n",
                "y_pred_final = final_model.predict(X_test_scaled)\n",
                "final_r2 = r2_score(y_test, y_pred_final)\n",
                "\n",
                "print(f\"Final Model ({best_model_name}) Test R2: {final_r2:.4f}\")\n",
                "\n",
                "# Save Model and Scaler\n",
                "joblib.dump(final_model, 'customer_model_best.pkl')\n",
                "joblib.dump(scaler, 'customer_scaler.pkl')\n",
                "\n",
                "print(\"Model and Scaler saved to disk.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Summary\n",
                "\n",
                "We have successfully:\n",
                "1. Compared 4 different algorithms using K-Fold Cross-Validation on the **Malaysia Customer Transactions** dataset.\n",
                "2. Visualized the results to make a data-driven choice.\n",
                "3. Selected the best model and saved it for future use.\n",
                "\n",
                "This concludes the model comparison module!"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}