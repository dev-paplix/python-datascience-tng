{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Neighbor-Based Predictions: K-Nearest Neighbors (KNN)\n",
                "\n",
                "## Neighbor-Based Learning\n",
                "\n",
                "In previous sessions, we used Tree-based models (Random Forest, XGBoost) which split data by rules.\n",
                "Now we introduce **K-Nearest Neighbors (KNN)** — an *instance-based* learner that assumes similar customers have similar spending patterns.\n",
                "\n",
                "**Dataset**: Malaysia Customer Transactions 2025 — predicting `total_transaction_amount`.\n",
                "\n",
                "**How KNN Works:**\n",
                "1. **Store** all training data.\n",
                "2. For a new prediction, calculate the **distance** to all training points.\n",
                "3. Find the **K** nearest neighbors.\n",
                "4. **Average** their target values (for Regression) as the prediction.\n",
                "\n",
                "**Key Difference from Trees:**\n",
                "- KNN is sensitive to the **scale** of data (because it uses distance).\n",
                "- Trees are invariant to scale."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "# Scikit-Learn tools\n",
                "from sklearn.neighbors import KNeighborsRegressor\n",
                "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
                "from sklearn.model_selection import train_test_split, GridSearchCV\n",
                "from sklearn.metrics import mean_squared_error, r2_score\n",
                "\n",
                "%matplotlib inline\n",
                "sns.set_theme(style=\"whitegrid\")\n",
                "plt.rcParams['figure.figsize'] = (10, 6)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Data Loading & Preprocessing\n",
                "\n",
                "**Critical Step: Scaling**\n",
                "Unlike XGBoost, KNN *requires* feature scaling.\n",
                "Consider two features:\n",
                "- `region_encoded`: range 0–15 (16 Malaysian states)\n",
                "- `number_of_purchases`: range 0–25\n",
                "\n",
                "Without scaling, distances might be dominated by one feature. We use `StandardScaler` (mean=0, variance=1) to normalise."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load data\n",
                "df = pd.read_csv(\"dummy_malaysia_customer_transactions_2025.csv\")\n",
                "\n",
                "# Encode categorical features\n",
                "le_region = LabelEncoder()\n",
                "le_quarter = LabelEncoder()\n",
                "df['region_encoded'] = le_region.fit_transform(df['region'].fillna('Unknown'))\n",
                "df['quarter_encoded'] = le_quarter.fit_transform(df['quarter'].fillna('Unknown'))\n",
                "\n",
                "# Select Features and Target\n",
                "features = ['region_encoded', 'quarter_encoded', 'number_of_purchases']\n",
                "target = 'total_transaction_amount'\n",
                "\n",
                "data = df[features + [target]].dropna()\n",
                "X = data[features]\n",
                "y = data[target]\n",
                "\n",
                "# Split Data\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "\n",
                "# Scale Data\n",
                "scaler = StandardScaler()\n",
                "X_train_scaled = scaler.fit_transform(X_train)\n",
                "X_test_scaled = scaler.transform(X_test)\n",
                "\n",
                "print(f\"Training Data Shape: {X_train.shape}\")\n",
                "print(\"Data has been scaled.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Baseline KNN Model\n",
                "\n",
                "We train a standard KNN Regressor.\n",
                "Key parameter:\n",
                "- `n_neighbors`: The 'K' in KNN. Number of neighbors to use."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize model (default K=3)\n",
                "knn_model = KNeighborsRegressor(n_neighbors=3)\n",
                "\n",
                "# Train (on SCALED data)\n",
                "knn_model.fit(X_train_scaled, y_train)\n",
                "\n",
                "# Predict\n",
                "y_pred = knn_model.predict(X_test_scaled)\n",
                "\n",
                "# Evaluate\n",
                "mse = mean_squared_error(y_test, y_pred)\n",
                "r2 = r2_score(y_test, y_pred)\n",
                "\n",
                "print(\"--- Baseline KNN (K=3) ---\")\n",
                "print(f\"MSE: {mse:.2f}\")\n",
                "print(f\"R2 Score: {r2:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. The Effect of 'K' (Overfitting vs Underfitting)\n",
                "\n",
                "The choice of K dramatically changes the model:\n",
                "- **Small K (e.g., 1)**: Captures noise — **Overfitting** (High Variance).\n",
                "- **Large K**: Averages too many points — **Underfitting** (High Bias).\n",
                "\n",
                "Let's visualize how the error changes as we increase K."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "k_values = range(1, 21)\n",
                "mse_scores = []\n",
                "\n",
                "for k in k_values:\n",
                "    knn = KNeighborsRegressor(n_neighbors=k)\n",
                "    knn.fit(X_train_scaled, y_train)\n",
                "    y_p = knn.predict(X_test_scaled)\n",
                "    mse_scores.append(mean_squared_error(y_test, y_p))\n",
                "\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.plot(k_values, mse_scores, marker='o', linestyle='--')\n",
                "plt.title('MSE vs. n_neighbors (K) — Customer Transactions')\n",
                "plt.xlabel('K')\n",
                "plt.ylabel('Mean Squared Error')\n",
                "plt.xticks(k_values)\n",
                "plt.grid(True)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Hyperparameter Tuning\n",
                "\n",
                "We can tune:\n",
                "- `n_neighbors`: The number of neighbors.\n",
                "- `weights`: 'uniform' (all neighbors equal) vs 'distance' (closer neighbors have more say).\n",
                "- `p`: Distance metric. 1 = Manhattan (L1), 2 = Euclidean (L2)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "param_grid = {\n",
                "    'n_neighbors': [3, 5, 7, 9, 11, 15],\n",
                "    'weights': ['uniform', 'distance'],\n",
                "    'p': [1, 2]\n",
                "}\n",
                "\n",
                "knn_tuned = KNeighborsRegressor()\n",
                "grid_search = GridSearchCV(estimator=knn_tuned, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', verbose=1)\n",
                "grid_search.fit(X_train_scaled, y_train)\n",
                "\n",
                "best_knn = grid_search.best_estimator_\n",
                "\n",
                "print(f\"Best Params: {grid_search.best_params_}\")\n",
                "print(f\"Best CV MSE: {-grid_search.best_score_:.2f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Visualization: Actual vs Predicted\n",
                "\n",
                "KNN doesn't provide 'Feature Importance' like trees. We assess performance by how close predictions are to actual values."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "final_pred = best_knn.predict(X_test_scaled)\n",
                "\n",
                "plt.figure(figsize=(8, 8))\n",
                "sns.scatterplot(x=y_test, y=final_pred, alpha=0.6)\n",
                "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', linewidth=2)  # Identity line\n",
                "plt.xlabel('Actual Transaction Amount (MYR)')\n",
                "plt.ylabel('Predicted Transaction Amount (MYR)')\n",
                "plt.title('Actual vs Predicted (KNN) — Customer Transactions')\n",
                "plt.show()\n",
                "\n",
                "final_r2 = r2_score(y_test, final_pred)\n",
                "print(f\"Best KNN R2: {final_r2:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Exercises\n",
                "\n",
                "Challenge yourself with these tasks!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Task 1: The Effect of Scaling\n",
                "# Train a KNN model (K=5) on the UN-SCALED data (X_train, X_test).\n",
                "# Compare the MSE with the scaled version. How big is the difference?\n",
                "\n",
                "# Your code here"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Task 2: Manual Inference\n",
                "# Pick a random row from X_test.\n",
                "# Find its nearest neighbor manually using numpy (Euclidean distance on scaled data).\n",
                "# Does the target value of the neighbor match the prediction?\n",
                "\n",
                "# Your code here"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Summary\n",
                "\n",
                "You've learned **K-Nearest Neighbors**!\n",
                "1. **Similarity-based**: Predicts based on what is close.\n",
                "2. **Scaling is Key**: Distances are distorted without proper scaling.\n",
                "3. **Choice of K**: Balances noise (small K) vs smoothness (large K)."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}